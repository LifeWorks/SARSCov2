{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hypernetx as hnx\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = pd.read_pickle(\"biggerTrans.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dffwos2 = pd.read_pickle(\"biggerTransNoSars2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dffwos = pd.read_pickle(\"biggerTransNoSars.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dffwoc = pd.read_pickle(\"biggerTransNoCov.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the hypergraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9524, 169)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we use some (though not all) of the from_dataframe() arguments and\n",
    "# let the function take care of the dataframe manipulation\n",
    "Hf = hnx.Hypergraph.from_dataframe(dff, # the whole dataframe, b and p columns\n",
    "                                                    #columns=human_b_cols, # choose specific columns\n",
    "                                                    zsc='columns', # other option is 'rows'\n",
    "                                                    absolute=True, # absolute value after z-score is taken\n",
    "                                                    lower_thresh=2) # applies the > 2 threshold after zscore and absolute value)\n",
    "\n",
    "# options that I used the defaults for:\n",
    "# transpose = False: this will transpose the dataframe after z-score and absolute value, essentially creating the dual hypergraph. Instead we're taking the dual after the fact (below).\n",
    "# name = None (string): If you want to give the resulting hypergraph a \"name\" attribute. Not necessary.\n",
    "# key = None (function which evaluates True or False): This is for more complcated thresholding. If you're just doing z-score > some threshold you don't need to worry about this.\n",
    "# rows = None (list of row names): If you want to use only a subset of the rows. This is done before taking z-score so your z-score will be relative only to those rows chosen.\n",
    "# upper_thresh = None (number): You can have a maximum value for the the zscore if you want. You can use both upper_thresh and lower_thresh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running example here for large s value because it finishes relatively quickly. \n",
    "# Small s values take a long time on these large hypergraphs!\n",
    "#betcen30 = hnx.s_betweenness_centrality(HfD, s=30)\n",
    "#clocen30 = hnx.s_harmonic_closeness_centrality(HfD, s=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8010, 159)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159, 8010)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HfD = Hf.dual()\n",
    "HfD.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we use some (though not all) of the from_dataframe() arguments and\n",
    "# let the function take care of the dataframe manipulation\n",
    "Hfwos2 = hnx.Hypergraph.from_dataframe(dffwos2, # the whole dataframe, b and p columns\n",
    "                                                    #columns=human_b_cols, # choose specific columns\n",
    "                                                    zsc='columns', # other option is 'rows'\n",
    "                                                    absolute=True, # absolute value after z-score is taken\n",
    "                                                    lower_thresh=2) # applies the > 2 threshold after zscore and absolute value)\n",
    "\n",
    "# options that I used the defaults for:\n",
    "# transpose = False: this will transpose the dataframe after z-score and absolute value, essentially creating the dual hypergraph. Instead we're taking the dual after the fact (below).\n",
    "# name = None (string): If you want to give the resulting hypergraph a \"name\" attribute. Not necessary.\n",
    "# key = None (function which evaluates True or False): This is for more complcated thresholding. If you're just doing z-score > some threshold you don't need to worry about this.\n",
    "# rows = None (list of row names): If you want to use only a subset of the rows. This is done before taking z-score so your z-score will be relative only to those rows chosen.\n",
    "# upper_thresh = None (number): You can have a maximum value for the the zscore if you want. You can use both upper_thresh and lower_thresh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7960, 154)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hfwos2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hfwos2D = Hfwos2.dual()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154, 7960)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hfwos2D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Hfwos2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-23 13:51:57,613\tINFO resource_spec.py:204 -- Starting Ray with 10.11 GiB memory available for workers and up to 5.07 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2020-05-23 13:51:58,319\tINFO services.py:1168 -- View the Ray dashboard at \u001b[1m\u001b[32mlocalhost:8267\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '130.20.194.73',\n",
       " 'raylet_ip_address': '130.20.194.73',\n",
       " 'redis_address': '130.20.194.73:27330',\n",
       " 'object_store_address': '/tmp/ray/session_2020-05-23_13-51-57_585122_51512/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2020-05-23_13-51-57_585122_51512/sockets/raylet',\n",
       " 'webui_url': 'localhost:8267',\n",
       " 'session_dir': '/tmp/ray/session_2020-05-23_13-51-57_585122_51512'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init(num_cpus=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def betweenness(s, graph = graph):\n",
    "    sbt = hnx.s_betweenness_centrality(graph, s=s)\n",
    "    sbt = pd.Series(sbt)\n",
    "    sbt.to_pickle(\"intermediateNoSars2/\" + str(s) + \"-betweenness.pkl\")\n",
    "    return(sbt)\n",
    "\n",
    "@ray.remote\n",
    "def closeness(s, graph = graph):\n",
    "    scl = hnx.s_harmonic_closeness_centrality(graph, s=s)\n",
    "    scl = pd.Series(scl)\n",
    "    scl.to_pickle(\"intermediateNoSars2/\" + str(s) + \"-closeness.pkl\")\n",
    "    return(scl)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Hfwos2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hfwos2Dscl = ray.get([closeness.remote(i) for i in range(1,51)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
