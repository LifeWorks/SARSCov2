{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hypernetx as hnx\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = pd.read_pickle(\"biggerTrans.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dffwos2 = pd.read_pickle(\"biggerTransNoSars2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dffwos = pd.read_pickle(\"biggerTransNoSars.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dffwoc = pd.read_pickle(\"biggerTransNoCov.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the hypergraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9524, 169)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we use some (though not all) of the from_dataframe() arguments and\n",
    "# let the function take care of the dataframe manipulation\n",
    "Hf = hnx.Hypergraph.from_dataframe(dff, # the whole dataframe, b and p columns\n",
    "                                                    #columns=human_b_cols, # choose specific columns\n",
    "                                                    zsc='columns', # other option is 'rows'\n",
    "                                                    absolute=True, # absolute value after z-score is taken\n",
    "                                                    lower_thresh=2) # applies the > 2 threshold after zscore and absolute value)\n",
    "\n",
    "# options that I used the defaults for:\n",
    "# transpose = False: this will transpose the dataframe after z-score and absolute value, essentially creating the dual hypergraph. Instead we're taking the dual after the fact (below).\n",
    "# name = None (string): If you want to give the resulting hypergraph a \"name\" attribute. Not necessary.\n",
    "# key = None (function which evaluates True or False): This is for more complcated thresholding. If you're just doing z-score > some threshold you don't need to worry about this.\n",
    "# rows = None (list of row names): If you want to use only a subset of the rows. This is done before taking z-score so your z-score will be relative only to those rows chosen.\n",
    "# upper_thresh = None (number): You can have a maximum value for the the zscore if you want. You can use both upper_thresh and lower_thresh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running example here for large s value because it finishes relatively quickly. \n",
    "# Small s values take a long time on these large hypergraphs!\n",
    "#betcen30 = hnx.s_betweenness_centrality(HfD, s=30)\n",
    "#clocen30 = hnx.s_harmonic_closeness_centrality(HfD, s=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8010, 159)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159, 8010)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HfD = Hf.dual()\n",
    "HfD.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we use some (though not all) of the from_dataframe() arguments and\n",
    "# let the function take care of the dataframe manipulation\n",
    "Hfwos2 = hnx.Hypergraph.from_dataframe(dffwos2, # the whole dataframe, b and p columns\n",
    "                                                    #columns=human_b_cols, # choose specific columns\n",
    "                                                    zsc='columns', # other option is 'rows'\n",
    "                                                    absolute=True, # absolute value after z-score is taken\n",
    "                                                    lower_thresh=2) # applies the > 2 threshold after zscore and absolute value)\n",
    "\n",
    "# options that I used the defaults for:\n",
    "# transpose = False: this will transpose the dataframe after z-score and absolute value, essentially creating the dual hypergraph. Instead we're taking the dual after the fact (below).\n",
    "# name = None (string): If you want to give the resulting hypergraph a \"name\" attribute. Not necessary.\n",
    "# key = None (function which evaluates True or False): This is for more complcated thresholding. If you're just doing z-score > some threshold you don't need to worry about this.\n",
    "# rows = None (list of row names): If you want to use only a subset of the rows. This is done before taking z-score so your z-score will be relative only to those rows chosen.\n",
    "# upper_thresh = None (number): You can have a maximum value for the the zscore if you want. You can use both upper_thresh and lower_thresh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7960, 154)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hfwos2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hfwos2D = Hfwos2.dual()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154, 7960)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hfwos2D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = HfD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-23 13:48:29,024\tINFO resource_spec.py:204 -- Starting Ray with 9.96 GiB memory available for workers and up to 5.0 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2020-05-23 13:48:29,408\tINFO services.py:1168 -- View the Ray dashboard at \u001b[1m\u001b[32mlocalhost:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '130.20.194.73',\n",
       " 'raylet_ip_address': '130.20.194.73',\n",
       " 'redis_address': '130.20.194.73:55826',\n",
       " 'object_store_address': '/tmp/ray/session_2020-05-23_13-48-29_006939_51506/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2020-05-23_13-48-29_006939_51506/sockets/raylet',\n",
       " 'webui_url': 'localhost:8265',\n",
       " 'session_dir': '/tmp/ray/session_2020-05-23_13-48-29_006939_51506'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init(num_cpus=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def betweenness(s, graph = graph):\n",
    "    sbt = hnx.s_betweenness_centrality(graph, s=s)\n",
    "    sbt = pd.Series(sbt)\n",
    "    sbt.to_pickle(\"intermediateNoSars2/\" + str(s) + \"-betweenness.pkl\")\n",
    "    return(sbt)\n",
    "\n",
    "@ray.remote\n",
    "def closeness(s, graph = graph):\n",
    "    scl = hnx.s_harmonic_closeness_centrality(graph, s=s)\n",
    "    scl = pd.Series(scl)\n",
    "    scl.to_pickle(\"intermediateNoSars2/\" + str(s) + \"-closeness.pkl\")\n",
    "    return(scl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Hfwos2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-23 14:14:48,715\tWARNING worker.py:1090 -- The monitor failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/feng626/anaconda3/envs/network/lib/python3.8/site-packages/redis/connection.py\", line 190, in _read_from_socket\n",
      "    data = recv(self._sock, socket_read_size)\n",
      "  File \"/Users/feng626/anaconda3/envs/network/lib/python3.8/site-packages/redis/_compat.py\", line 71, in recv\n",
      "    return sock.recv(*args, **kwargs)\n",
      "TimeoutError: [Errno 60] Operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/feng626/anaconda3/envs/network/lib/python3.8/site-packages/ray/monitor.py\", line 315, in <module>\n",
      "    monitor.run()\n",
      "  File \"/Users/feng626/anaconda3/envs/network/lib/python3.8/site-packages/ray/monitor.py\", line 260, in run\n",
      "    self._run()\n",
      "  File \"/Users/feng626/anaconda3/envs/network/lib/python3.8/site-packages/ray/monitor.py\", line 211, in _run\n",
      "    self.update_raylet_map()\n",
      "  File \"/Users/feng626/anaconda3/envs/network/lib/python3.8/site-packages/ray/monitor.py\", line 180, in update_raylet_map\n",
      "    all_raylet_nodes = ray.nodes()\n",
      "  File \"/Users/feng626/anaconda3/envs/network/lib/python3.8/site-packages/ray/state.py\", line 1008, in nodes\n",
      "    return state.client_table()\n",
      "  File \"/Users/feng626/anaconda3/envs/network/lib/python3.8/site-packages/ray/state.py\", line 379, in client_table\n",
      "    client_table = _parse_client_table(self.redis_client)\n",
      "  File \"/Users/feng626/anaconda3/envs/network/lib/python3.8/site-packages/ray/state.py\", line 29, in _parse_client_table\n",
      "    message = redis_client.execute_command(\n",
      "  File \"/Users/feng626/anaconda3/envs/network/lib/python3.8/site-packages/redis/client.py\", line 878, in execute_command\n",
      "    return self.parse_response(conn, command_name, **options)\n",
      "  File \"/Users/feng626/anaconda3/envs/network/lib/python3.8/site-packages/redis/client.py\", line 892, in parse_response\n",
      "    response = connection.read_response()\n",
      "  File \"/Users/feng626/anaconda3/envs/network/lib/python3.8/site-packages/redis/connection.py\", line 734, in read_response\n",
      "    response = self._parser.read_response()\n",
      "  File \"/Users/feng626/anaconda3/envs/network/lib/python3.8/site-packages/redis/connection.py\", line 316, in read_response\n",
      "    response = self._buffer.readline()\n",
      "  File \"/Users/feng626/anaconda3/envs/network/lib/python3.8/site-packages/redis/connection.py\", line 248, in readline\n",
      "    self._read_from_socket()\n",
      "  File \"/Users/feng626/anaconda3/envs/network/lib/python3.8/site-packages/redis/connection.py\", line 214, in _read_from_socket\n",
      "    raise ConnectionError(\"Error while reading from socket: %s\" %\n",
      "redis.exceptions.ConnectionError: Error while reading from socket: (60, 'Operation timed out')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E0523 15:23:57.143980 274400704 node_manager.cc:3537] Failed to send get core worker stats request: IOError: 14: Operation timed out\n",
      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E0523 15:23:57.146301 274400704 node_manager.cc:3537] Failed to send get core worker stats request: IOError: 14: Operation timed out\n",
      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E0523 15:23:57.146435 274400704 node_manager.cc:3537] Failed to send get core worker stats request: IOError: 14: Operation timed out\n",
      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E0523 15:23:57.146550 274400704 node_manager.cc:3537] Failed to send get core worker stats request: IOError: 14: Operation timed out\n",
      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E0523 15:23:57.146718 274400704 node_manager.cc:3537] Failed to send get core worker stats request: IOError: 14: Operation timed out\n",
      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E0523 15:23:57.146823 274400704 node_manager.cc:3537] Failed to send get core worker stats request: IOError: 14: Operation timed out\n",
      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E0523 15:23:57.146926 274400704 node_manager.cc:3537] Failed to send get core worker stats request: IOError: 14: Operation timed out\n",
      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E0523 15:23:57.147023 274400704 node_manager.cc:3537] Failed to send get core worker stats request: IOError: 14: Operation timed out\n",
      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E0523 15:23:57.147159 274400704 node_manager.cc:3537] Failed to send get core worker stats request: IOError: 14: Operation timed out\n",
      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E0523 15:23:57.147262 274400704 node_manager.cc:3537] Failed to send get core worker stats request: IOError: 14: Operation timed out\n",
      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E0523 15:23:57.147356 274400704 node_manager.cc:3537] Failed to send get core worker stats request: IOError: 14: Operation timed out\n",
      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E0523 15:23:57.147444 274400704 node_manager.cc:3537] Failed to send get core worker stats request: IOError: 14: Operation timed out\n",
      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E0523 15:23:57.147578 274400704 node_manager.cc:3537] Failed to send get core worker stats request: IOError: 14: Operation timed out\n",
      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E0523 15:23:57.147677 274400704 node_manager.cc:3537] Failed to send get core worker stats request: IOError: 14: Operation timed out\n",
      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E0523 15:23:57.147775 274400704 node_manager.cc:3537] Failed to send get core worker stats request: IOError: 14: Operation timed out\n",
      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E0523 15:23:57.147876 274400704 node_manager.cc:3537] Failed to send get core worker stats request: IOError: 14: Operation timed out\n",
      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E0523 15:23:57.147974 274400704 node_manager.cc:3537] Failed to send get core worker stats request: IOError: 14: Operation timed out\n",
      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E0523 15:23:57.148069 274400704 node_manager.cc:3537] Failed to send get core worker stats request: IOError: 14: Operation timed out\n",
      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E0523 15:23:57.148165 274400704 node_manager.cc:3537] Failed to send get core worker stats request: IOError: 14: Operation timed out\n"
     ]
    }
   ],
   "source": [
    "Hfwos2Dsbt = ray.get([betweenness.remote(i) for i in range(1,51)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
